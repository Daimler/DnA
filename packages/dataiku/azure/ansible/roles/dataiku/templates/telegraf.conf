[global_tags]
  hostname = "{{dataiku_hostname.stdout}}"

[agent]
  interval = "10s"
  round_interval = true
  metric_batch_size = 200
  metric_buffer_limit = 1000
  collection_jitter = "0s"
  flush_interval = "10s"
  flush_jitter = "0s"
  precision = ""
  logtarget = "stderr"
  ## Override default hostname, if empty use os.Hostname()
  hostname = ""
  ## If set to true, do no set the "host" tag in the telegraf agent.
  omit_hostname = false


###############################################################################
#                            OUTPUT PLUGINS                                   #
###############################################################################


# Send aggregate metrics to Azure Monitor
[[outputs.azure_monitor]]

# Send aggregate metrics to Pushgateway
[[outputs.http]]
  url = "{{metrics_endpoint}}"
  method = "PUT"
  data_format = "prometheus" 

# Send aggregate metrics to Grafana
# [[outputs.http]]
#   url = "{{grafana_url}}"
#   data_format = "influx"
#   [outputs.http.headers]
#     Authorization = "{{grafana_api_key}}"
###############################################################################
#                            INPUT PLUGINS                                    #
###############################################################################


# Read metrics about cpu usage
[[inputs.cpu]]
  percpu = true
  totalcpu = true
  collect_cpu_time = false
  report_active = false
  ## metrics to emit
  fieldpass = ["usage_system", "usage_user", "usage_idle"]

# Read metrics about memory usage
[[inputs.mem]]
  ## metrics to emit
  fieldpass = ["active", "available_percent", "used_percent", "Free"]

# Check the http response on a healthcheck endpoint
[[inputs.http_response]]
  name_override = 'dss_healthcheck'
  urls = ["http://localhost:{{dss_port}}/dip/api/get-configuration"]
  method = "GET"
  data_format = "json"
  response_status_code = 200
  ## metrics to emit
  fieldpass = ["response_status_code_match"]

# Get the number of active dss users
[[inputs.http]]
  name_override = 'dss_active_users'
  urls = ["http://localhost:{{dss_port}}/public/api/admin/users/?connected=true"]
  method = "GET"
  username = "{{dataiku_api_key.stdout}}"
  data_format = "json"
  ## metrics to emit
  fieldpass = ["activeWebSocketS*"]

[[inputs.http]]
  name_override = "run_ad_sync_status"
  urls = ["http://localhost:{{dss_port}}/public/api/projects/ADMIN_MACROS/scenarios/run_ad_sync/get-last-runs/?limit=1"]
  method = "GET"
  username = "{{dataiku_api_key.stdout}}"
  data_format = "json"
  # step necessary to let processor convert string to int
  tag_keys = ["result_outcome"]
  fieldpass = ["result_start"]

# Read metrics about disk usage
[[inputs.disk]]
  ## metrics to emit
  fieldpass = ["total", "free", "used_percent"]

# Parse logs
[[inputs.tail]]
  from_beginning = false
  max_undelivered_lines = 1000
  files = ["/data/dataiku/run/backend.log"]
  data_format = "grok"
  grok_patterns = ['%{API_KEY:log_value:string}']
  grok_custom_patterns = '''
    API_KEY (?:create-project-api-key)
  '''
[[aggregators.valuecounter]]
  period = "40s"
  fields = ["log_value"]

[[aggregators.valuecounter]]
  period = "5s"
  fields = ["activeWebSocketSesssions"]

# change tag to field
[[processors.converter]]
  order = 1
  [processors.converter.tags]
    string = ["result_outcome"]

# change string field to enum values
[[processors.enum]]
  order = 2
  [[processors.enum.mapping]]
    field = "result_outcome"
    [processors.enum.mapping.value_mappings]
      SUCCESS = 1
      FAILED = 0
